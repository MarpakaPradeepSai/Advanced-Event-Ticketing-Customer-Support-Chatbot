{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Required Libraries**"
      ],
      "metadata": {
        "id": "SOAriqAi9tF3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EWaUXGf69SwV"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    DistilBertTokenizerFast,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "\n",
        "from datasets import Dataset\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhR4DY7MAHd6",
        "outputId": "01e98588-fdde-4bf5-fcdc-d9a099e0c438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Full_data_for_classification_53745.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1CMBQGHc9UdJ",
        "outputId": "526539e2-f7bf-47c0-d286-ea8333147c11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             instruction         intent  OOD\n",
              "0      I'd like to cancel my ticket for the game in t...  cancel_ticket   No\n",
              "1      I have to cancel my ticket for the event in th...  cancel_ticket   No\n",
              "2      I have to cancel my ticket for the show i need...  cancel_ticket   No\n",
              "3      How could i cancel  my tickets for the show in...  cancel_ticket   No\n",
              "4      Wanna cancel my ticket for the show in this to...  cancel_ticket   No\n",
              "...                                                  ...            ...  ...\n",
              "53740  Morning! Hope you're feeling vibrant and full ...       greeting  Yes\n",
              "53741  Hey there, what's filling your heart with pure...       greeting  Yes\n",
              "53742  Hru, any profound thoughts or quiet reflection...       greeting  Yes\n",
              "53743  Just dropping in to say hi and wish you an utt...       greeting  Yes\n",
              "53744  Yo, what's the situation, my absolutely wonder...       greeting  Yes\n",
              "\n",
              "[53745 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da1da825-a82c-40d2-88ea-8065f53117ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>intent</th>\n",
              "      <th>OOD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I'd like to cancel my ticket for the game in t...</td>\n",
              "      <td>cancel_ticket</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have to cancel my ticket for the event in th...</td>\n",
              "      <td>cancel_ticket</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I have to cancel my ticket for the show i need...</td>\n",
              "      <td>cancel_ticket</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How could i cancel  my tickets for the show in...</td>\n",
              "      <td>cancel_ticket</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wanna cancel my ticket for the show in this to...</td>\n",
              "      <td>cancel_ticket</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53740</th>\n",
              "      <td>Morning! Hope you're feeling vibrant and full ...</td>\n",
              "      <td>greeting</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53741</th>\n",
              "      <td>Hey there, what's filling your heart with pure...</td>\n",
              "      <td>greeting</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53742</th>\n",
              "      <td>Hru, any profound thoughts or quiet reflection...</td>\n",
              "      <td>greeting</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53743</th>\n",
              "      <td>Just dropping in to say hi and wish you an utt...</td>\n",
              "      <td>greeting</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53744</th>\n",
              "      <td>Yo, what's the situation, my absolutely wonder...</td>\n",
              "      <td>greeting</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53745 rows \u00d7 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da1da825-a82c-40d2-88ea-8065f53117ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da1da825-a82c-40d2-88ea-8065f53117ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da1da825-a82c-40d2-88ea-8065f53117ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c8ced254-32e6-4879-81c5-1d17749c1fdf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8ced254-32e6-4879-81c5-1d17749c1fdf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c8ced254-32e6-4879-81c5-1d17749c1fdf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f8e84bb1-896c-4c96-b874-912ab162be60\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f8e84bb1-896c-4c96-b874-912ab162be60 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 53745,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 53745,\n        \"samples\": [\n          \"Discuss the principles of social democracy.\",\n          \"What is the concept of genetic engineering for new vaccine development?\",\n          \"Who wrote 'The Divine Comedy'?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 55,\n        \"samples\": [\n          \"law\",\n          \"event_organizer\",\n          \"science\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OOD\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2TaFUVY_Cbb",
        "outputId": "668746ef-e2fd-4dec-d1dd-76c757751830"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53745 entries, 0 to 53744\n",
            "Data columns (total 3 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   instruction  53745 non-null  object\n",
            " 1   intent       53745 non-null  object\n",
            " 2   OOD          53745 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for NULL values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "WzBaNsur9gHr",
        "outputId": "e8d88db7-6342-4d6c-eb7e-cb8942d3bd1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "instruction    0\n",
              "intent         0\n",
              "OOD            0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>instruction</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intent</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OOD</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for duplicates\n",
        "print(df['instruction'].duplicated().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6orIHqH-1UA",
        "outputId": "e035cc31-a5f6-44bc-df04-a1f5bf24b891"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "# Convert OOD column to binary labels: Yes -> 1, No -> 0\n",
        "df['label'] = df['OOD'].apply(lambda x: 1 if x == 'Yes' else 0)"
      ],
      "metadata": {
        "id": "rJR7MHOd9jRn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and validation sets (85-15 split)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['instruction'].tolist(),\n",
        "    df['label'].tolist(),\n",
        "    test_size=0.15,\n",
        "    random_state=42,\n",
        "    stratify=df['intent']\n",
        ")"
      ],
      "metadata": {
        "id": "kkrSguMZ9jOt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#     "
      ],
      "metadata": {
        "id": "qijhpKNl7eyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DistilBERT-base-uncased: A Distilled Version of BERT-base-uncased**\n",
        "\n",
        "**`DistilBERT-base-uncased`** is a smaller, faster, and lighter version of Google\u2019s **`BERT-base-uncased`**, created using **knowledge distillation**. It was developed by **Hugging Face** to retain most of BERT\u2019s performance on NLP tasks while reducing computational overhead \u2014 making it ideal for deployment in production environments with latency or memory constraints.\n",
        "\n",
        "---\n",
        "\n",
        "## **Key Features of DistilBERT-base-uncased**\n",
        "\n",
        "1. **Smaller Model Size**  \n",
        "   - BERT-base has **110M parameters**; DistilBERT has **66M parameters** (~40% reduction).\n",
        "   - Retains the same hidden size (768) but reduces transformer layers from 12 to 6.\n",
        "\n",
        "2. **Retained Performance**  \n",
        "   - Achieves **~95% of BERT\u2019s performance** on key benchmarks like GLUE.\n",
        "   - Particularly strong on classification, NER, and QA tasks after fine-tuning.\n",
        "\n",
        "3. **Knowledge Distillation**  \n",
        "   - Trained as a \u201cstudent\u201d model to mimic the behavior of the \u201cteacher\u201d BERT.\n",
        "   - Uses three loss components during training:\n",
        "     - **Soft target loss**: Matches output probabilities (logits) of BERT.\n",
        "     - **Hard label loss**: Standard cross-entropy on ground-truth labels.\n",
        "     - **Cosine embedding loss**: Aligns hidden state representations layer-wise.\n",
        "\n",
        "4. **Faster Inference & Training**  \n",
        "   - **60% faster inference** than BERT-base due to half the layers.\n",
        "   - Reduced memory footprint enables deployment on CPUs or edge devices.\n",
        "\n",
        "5. **Uncased Tokenization**  \n",
        "   - Input text is lowercased before tokenization \u2014 suitable for case-insensitive tasks.\n",
        "   - Uses WordPiece tokenizer (same as BERT), vocabulary size = 30,522.\n",
        "\n",
        "6. **Open-Source & MIT Licensed**  \n",
        "   - Freely available via Hugging Face `transformers` library.\n",
        "   - Can be fine-tuned for commercial applications without restrictions.\n",
        "\n",
        "---\n",
        "\n",
        "## **Architecture Differences (vs. BERT-base-uncased)**\n",
        "\n",
        "| Feature             | BERT-base-uncased | DistilBERT-base-uncased |\n",
        "|---------------------|-------------------|--------------------------|\n",
        "| **Parameters**        | 110M              | 66M                      |\n",
        "| **Transformer Layers** | 12                | 6                        |\n",
        "| **Attention Heads**    | 12                | 12                       |\n",
        "| **Hidden Size**       | 768               | 768                      |\n",
        "| **Feedforward Dim**   | 3072              | 3072                     |\n",
        "| **Max Sequence Length** | 512 tokens        | 512 tokens               |\n",
        "| **Tokenizer**         | WordPiece (uncased) | WordPiece (uncased)      |\n",
        "| **Positional Encoding** | Learned           | Learned                  |\n",
        "\n",
        "- DistilBERT removes the **pooler layer** (used for next sentence prediction in BERT).\n",
        "- No NSP (Next Sentence Prediction) task used during pre-training \u2014 only masked language modeling.\n",
        "- Layer initialization: First 6 layers of BERT are copied to initialize DistilBERT (then fine-tuned).\n",
        "\n",
        "---\n",
        "\n",
        "## **Training Process**\n",
        "\n",
        "1. **Pre-training Dataset**  \n",
        "   - Trained on the same data as BERT: **BookCorpus + English Wikipedia** (~13GB text).\n",
        "\n",
        "2. **Knowledge Distillation Setup**  \n",
        "   - Teacher: BERT-base-uncased.\n",
        "   - Student: 6-layer Transformer initialized from teacher\u2019s first 6 layers.\n",
        "   - Trained using **masked language modeling (MLM)** objective only \u2014 no NSP.\n",
        "\n",
        "3. **Loss Functions Combined**  \n",
        "   The total loss is a weighted sum:\n",
        "   ```\n",
        "   Loss = \u03b1 * L_{ce} + \u03b2 * L_{distill} + \u03b3 * L_{cos}\n",
        "   ```\n",
        "   - `L_{ce}`: Cross-entropy loss on true labels.\n",
        "   - `L_{distill}`: KL-divergence between student and teacher softmax outputs.\n",
        "   - `L_{cos}`: Cosine similarity loss between corresponding hidden states.\n",
        "\n",
        "   Default weights: \u03b1=1.0, \u03b2=5.0, \u03b3=0.5 (from original paper).\n",
        "\n",
        "4. **Optimization Details**  \n",
        "   - Optimizer: **AdamW** (weight decay = 0.01).\n",
        "   - Learning rate: 5e-4 with linear warmup and decay.\n",
        "   - Batch size: 256 sequences.\n",
        "   - Trained for **~90 hours** on 8x 16GB V100 GPUs.\n",
        "\n",
        "---\n",
        "\n",
        "## **Performance Comparison**\n",
        "\n",
        "| Model                   | Params | Speed (Inference) | GLUE Avg Score (Higher better) | SQuAD v1.1 F1 |\n",
        "|------------------------|--------|-------------------|-------------------------------|---------------|\n",
        "| BERT-base-uncased      | 110M   | 1.0x (baseline)   | 78.3                          | 88.5          |\n",
        "| **DistilBERT-base-uncased** | **66M** | **~1.6x faster**  | **76.7**                      | **86.9**      |\n",
        "| MobileBERT (Google)    | 25M    | ~2x faster        | ~77.7                         | ~89.5         |\n",
        "\n",
        "- DistilBERT retains **~97% of BERT\u2019s GLUE score** with 40% fewer parameters.\n",
        "- On SQuAD, it loses only ~1.6 F1 points \u2014 negligible for many applications.\n",
        "- Outperforms similarly sized models like TinyBERT in generalization.\n",
        "\n",
        "---\n",
        "\n",
        "## **Use Cases**\n",
        "\n",
        "1. **Text Classification**  \n",
        "   - Sentiment analysis, spam detection, topic labeling \u2014 ideal due to speed and accuracy trade-off.\n",
        "\n",
        "2. **Named Entity Recognition (NER)**  \n",
        "   - Efficiently tags entities in real-time systems (e.g., customer support logs).\n",
        "\n",
        "3. **Question Answering (QA)**  \n",
        "   - Suitable for extractive QA on constrained devices (mobile, browser extensions).\n",
        "\n",
        "4. **Semantic Search & Embeddings**  \n",
        "   - Generate sentence embeddings (with mean-pooling or [CLS]) for retrieval tasks.\n",
        "\n",
        "5. **Edge & Real-Time Applications**  \n",
        "   - Runs efficiently on CPU-only servers or mobile apps where latency matters.\n",
        "\n",
        "6. **Educational & Prototyping Use**  \n",
        "   - Excellent for learning transformer internals or rapid experimentation without GPU dependency.\n",
        "\n",
        "---\n",
        "\n",
        "## **Limitations**\n",
        "\n",
        "- **No Next Sentence Prediction (NSP)**: Not suitable out-of-the-box for tasks requiring inter-sentence reasoning (though rarely needed post-BERT).\n",
        "- **Slightly Weaker on Long Dependencies**: Due to fewer layers, may underperform on very long or complex linguistic structures.\n",
        "- **Not State-of-the-Art**: Newer distilled models (e.g., TinyBERT, MobileBERT, MiniLM) may offer better efficiency or performance.\n",
        "- **Still Larger Than Ultra-Light Models**: For extreme edge cases, consider even smaller models like `bert-tiny` (4M params)."
      ],
      "metadata": {
        "id": "tF98b4L62zK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DistilBERT model for binary classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247,
          "referenced_widgets": [
            "5213675edf0b4b299019b4648979f71e",
            "68e464acee0d4a55b1e247887e5c31c3",
            "1fb52224c2944bb7b26a3126d7f11742",
            "90c5663f87234ea4ad09ffa77e4ec8d2",
            "f38d6f1b06d2471d9d3cf2d40ef85c2d",
            "c5ceaee2858a4877ab4f46f99404b4e3",
            "40b469d8ca12450e928db34b048535a8",
            "3cdc3077f8214abe917a0defb4026d2f",
            "4d2f2dbaeaca437f9f2ed5fe211cc320",
            "60cf59463a0a4b9d864903127b51f1be",
            "1fb06c5f9b054184a309d9a521d64dcb",
            "4d7ebe4425e34c4abdd33300c1bf1eb8",
            "c1237b2956f3492d8c18d9649faf4359",
            "b4c22e49f30444f295b205bc65eac324",
            "73164dac1b32464d89b45a85b768ea02",
            "fa173df0309f4c879d96441c666b8922",
            "c73ae38c306e478897ade50ce8e73d25",
            "82be1de021294e7db47d5bb3690f3671",
            "f3c51b01b8934485991dc37181b44c93",
            "c97aad9293e74ed39f42b96aa59750c3",
            "8a360180252f4a9fa9442593e7399185",
            "d10b136fcb7849a5b21b73212039c0ee"
          ]
        },
        "id": "YFgGR2NM-j64",
        "outputId": "259f681b-73d2-4824-9727-1fa11a411a1f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5213675edf0b4b299019b4648979f71e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d7ebe4425e34c4abdd33300c1bf1eb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "b62aa13a4906440d9e2a70d370beca9f",
            "08b2ee0a196b4fbe9a17fc0ad74b271b",
            "c8cdefe218c7473194ab20738c98ac21",
            "d4ee1d1a48b44f249da9906865a2ce29",
            "0275d0c8041c4f39829ff6c3d55afb3e",
            "97072cf45e964546a4667afabd58dbe6",
            "a5d1ea5ce3704af4ae6e49dc17ba4737",
            "d9dc0f102c714c13a57c3d7e4d615a34",
            "f21c81fdbe4d434381db265cf7cce10c",
            "4088464a9c174e17b2e84f8874cd0966",
            "6c10c7cd62a44da59249c3e70743db46",
            "b9680df2971a40cd817b6de72e45c3b7",
            "db8586f93e3d4e9894b9d24092a6b52d",
            "6038401da11643d49ef2239c42e1fe2c",
            "d9b5e6aa6bc741b282d346b3bdf71505",
            "6410e4c04d8246b99ba777201ab064ab",
            "37dbda01fe2542409ad3c120bc2db5eb",
            "4eca13a37d39418983443103d4842f72",
            "a8c738233b494c3280500283ac5e5d51",
            "1befc61511f0453ab60d5cb953907c80",
            "ce260b0e88f94b6da7da6daee914d7d0",
            "04cd57bb04ac4a3eb3280c779fa00ef2",
            "3656ae9a09a54d67b826eeab075e7150",
            "e985c8af5554493fb1fdf29fa84383d9",
            "47c73cc1cf3b4a0ebc39338889ad5586",
            "985538a2760744e4bc0ab114246cec66",
            "8e0f210c15ab49a696039dd2c9634187",
            "cfc8c402542348999734f065f50b0737",
            "3f9614a725c740d690fdda699d25012b",
            "be6a7a86ea6046eb82433c3b8bdfe169",
            "d6356f123ac045408f3ed68ca9a154b2",
            "245eb6b362274ec1b01e8aff227250bd",
            "ce1b48b168cb471fb26a393fc9867802"
          ]
        },
        "id": "Vog4F4AC9jM4",
        "outputId": "7c475024-d0c1-44b2-e2c6-272b662fce0e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b62aa13a4906440d9e2a70d370beca9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9680df2971a40cd817b6de72e45c3b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3656ae9a09a54d67b826eeab075e7150"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data for both training and validation\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=256)"
      ],
      "metadata": {
        "id": "ih6LsYdz9jI-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to HuggingFace Dataset format\n",
        "train_dataset = Dataset.from_dict({\n",
        "    'input_ids': train_encodings['input_ids'],\n",
        "    'attention_mask': train_encodings['attention_mask'],\n",
        "    'labels': train_labels   # Note: key must be 'labels'\n",
        "})\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCxVDIVB9jG8",
        "outputId": "4f73162c-2f6c-4d29-f7e9-67522f4ebd1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 45683\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = Dataset.from_dict({\n",
        "    'input_ids': val_encodings['input_ids'],\n",
        "    'attention_mask': val_encodings['attention_mask'],\n",
        "    'labels': val_labels   # Note: key must be 'labels'\n",
        "})\n",
        "\n",
        "val_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-wbbVyx9jFA",
        "outputId": "c5d0de2e-e312-4d9f-a5a4-f5fccce5d7f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 8062\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision = precision_score(labels, predictions)\n",
        "    recall = recall_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        \"eval_accuracy\": accuracy,\n",
        "        \"eval_precision\": precision,\n",
        "        \"eval_recall\": recall,\n",
        "        \"eval_f1\": f1\n",
        "    }"
      ],
      "metadata": {
        "id": "OqFBgU-J-j4S"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_f1\",\n",
        "    save_total_limit=5,\n",
        "    learning_rate=2e-5,\n",
        "    lr_scheduler_type=\"linear\"\n",
        ")"
      ],
      "metadata": {
        "id": "5ozZbhPi-j2S"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb2sK2sp-j0L",
        "outputId": "11fe8838-13cb-48a9-cb84-e3011af4adf7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2881525764.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Login\n",
        "wandb.login(key=\"220f713778670bc7b215d4475838cb3fb88d4534\")\n",
        "\n",
        "# Initialize run\n",
        "wandb.init(project=\"chatbot_classification_model\", name=\"distilbert-binary-OOD\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "bbRSUmdA_iac",
        "outputId": "803a51d2-1a89-4989-b192-f8b3c04afd45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzlibbrary4\u001b[0m (\u001b[33mzlibbrary4-iit-hyderabad\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "creating run (0.0s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250914_153615-ojthcuii</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zlibbrary4-iit-hyderabad/jhbjhb/runs/ojthcuii' target=\"_blank\">kjmn-kjhb-lkjn</a></strong> to <a href='https://wandb.ai/zlibbrary4-iit-hyderabad/jhbjhb' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/zlibbrary4-iit-hyderabad/jhbjhb' target=\"_blank\">https://wandb.ai/zlibbrary4-iit-hyderabad/jhbjhb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/zlibbrary4-iit-hyderabad/jhbjhb/runs/ojthcuii' target=\"_blank\">https://wandb.ai/zlibbrary4-iit-hyderabad/jhbjhb/runs/ojthcuii</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/zlibbrary4-iit-hyderabad/jhbjhb/runs/ojthcuii?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f5629250200>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "qrsWfmyb-jxB",
        "outputId": "a3b9b675-1804-4cfe-9cbf-02a07183f0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='28555' max='28555' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [28555/28555 22:32, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005750</td>\n",
              "      <td>0.998760</td>\n",
              "      <td>0.997791</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.998771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002510</td>\n",
              "      <td>0.999628</td>\n",
              "      <td>0.999508</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.999631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007475</td>\n",
              "      <td>0.999380</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.999016</td>\n",
              "      <td>0.999385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003028</td>\n",
              "      <td>0.999752</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.999754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003207</td>\n",
              "      <td>0.999628</td>\n",
              "      <td>0.999508</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.999631</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=28555, training_loss=0.006935134352845627, metrics={'train_runtime': 1353.1022, 'train_samples_per_second': 168.808, 'train_steps_per_second': 21.103, 'total_flos': 2127483342000720.0, 'train_loss': 0.006935134352845627, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "print(\"Evaluation results:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "fcr94egf-jvB",
        "outputId": "c5a937f2-5671-489a-d1a9-aad0198750ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [504/504 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation results: {'eval_accuracy': 0.9997519225998511, 'eval_precision': 0.999754058042302, 'eval_recall': 0.999754058042302, 'eval_f1': 0.999754058042302, 'eval_loss': 0.0030281455256044865, 'eval_runtime': 8.8141, 'eval_samples_per_second': 914.67, 'eval_steps_per_second': 57.181, 'epoch': 5.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation set\n",
        "predictions = trainer.predict(val_dataset)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "OuBe62dv_GqV",
        "outputId": "dd9a7b97-0027-4e17-bfb9-7bdae07aae0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[-8.234556,  8.849662],\n",
              "       [-8.268248,  8.879897],\n",
              "       [ 8.516267, -8.687723],\n",
              "       ...,\n",
              "       [ 8.509247, -8.692003],\n",
              "       [-8.275925,  8.904369],\n",
              "       [ 8.466045, -8.668133]], dtype=float32), label_ids=array([1, 1, 0, ..., 0, 1, 0]), metrics={'test_loss': 0.0030281455256044865, 'test_eval_accuracy': 0.9997519225998511, 'test_eval_precision': 0.999754058042302, 'test_eval_recall': 0.999754058042302, 'test_eval_f1': 0.999754058042302, 'test_runtime': 9.272, 'test_samples_per_second': 869.503, 'test_steps_per_second': 54.357})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted labels\n",
        "pred_labels = torch.argmax(torch.tensor(predictions.predictions), dim=1)\n",
        "\n",
        "# Print classification report\n",
        "report = classification_report(val_labels, pred_labels.numpy(), target_names=[\"No\", \"Yes\"])\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m15Dc5MG_Gm3",
        "outputId": "c57ff9b6-5e71-4d73-f8a8-de2847807111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          No       1.00      1.00      1.00      3996\n",
            "         Yes       1.00      1.00      1.00      4066\n",
            "\n",
            "    accuracy                           1.00      8062\n",
            "   macro avg       1.00      1.00      1.00      8062\n",
            "weighted avg       1.00      1.00      1.00      8062\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model\n",
        "save_directory = '/content/drive/MyDrive/Chatbot_Query_Classifier/chatbot_query_classifier_distilbert_model'\n",
        "\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpQFlKed9Uat",
        "outputId": "30b320dd-1a3e-4611-fa43-7eccb8ee6e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Chatbot_Query_Classifier/chatbot_query_classifier_distilbert_model/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Chatbot_Query_Classifier/chatbot_query_classifier_distilbert_model/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Chatbot_Query_Classifier/chatbot_query_classifier_distilbert_model/vocab.txt',\n",
              " '/content/drive/MyDrive/Chatbot_Query_Classifier/chatbot_query_classifier_distilbert_model/added_tokens.json',\n",
              " '/content/drive/MyDrive/Chatbot_Query_Classifier/chatbot_query_classifier_distilbert_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#        "
      ],
      "metadata": {
        "id": "jYXguyM6g3oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "zW6w6Vt6g7Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6xyjhVO9UU6",
        "outputId": "461b597d-53fe-4bae-edcb-4af0325f7446"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# \ud83d\udd01 Load the model and tokenizer from your saved directory\n",
        "model_path = '/content/mydrive/MyDrive/Chatbot_Query_Classifier/chatbot_query_classifier_distilbert_model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# \ud83d\udd12 Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# \u2705 Set device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# \u2705 Inference function\n",
        "def predict_OOD(query):\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predicted_class_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    label_map = {0: \"No\", 1: \"Yes\"}  # 0 = in-domain, 1 = out-of-domain\n",
        "    prediction_label = label_map[predicted_class_id]\n",
        "\n",
        "    return prediction_label"
      ],
      "metadata": {
        "id": "_6ZcCw0j9US6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \ud83d\udde8\ufe0f Run inference exactly TWICE\n",
        "print(\"\\n\ud83e\udd16 Please enter 2 queries:\")\n",
        "\n",
        "for i in range(2):\n",
        "    user_input = input(f\"[{i+1}/2] Your query: \")\n",
        "\n",
        "    # Optional: Allow early exit\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"\ud83d\udc4b Exiting early. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    prediction = predict_OOD(user_input)\n",
        "    print(f\"\ud83d\udccc Prediction (Is OOD?): {prediction}\\n\")\n",
        "\n",
        "print(\"\u2705 Done. Thank you!\")"
      ],
      "metadata": {
        "id": "IGbkKMrdFSs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55852f8-17f6-49aa-bd55-71128cec9de1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\ud83e\udd16 Please enter 2 queries:\n",
            "[1/2] Your query: How can i cancel my ticket?\n",
            "\ud83d\udccc Prediction (Is OOD?): No\n",
            "\n",
            "[2/2] Your query: what is quantum physics?\n",
            "\ud83d\udccc Prediction (Is OOD?): Yes\n",
            "\n",
            "\u2705 Done. Thank you!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  "
      ],
      "metadata": {
        "id": "TxdgiqyRg_Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference with Fallback responses**"
      ],
      "metadata": {
        "id": "m-jUoCdjhAwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jQdLuV5js9s",
        "outputId": "647fafea-50f8-4dea-92c9-3d2c786b55c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# List of fallback responses for OOD (Yes) predictions\n",
        "responses = [\n",
        "    \"I\u2019m sorry, but I am unable to assist with this request. If you need help regarding event tickets, I\u2019d be happy to support you.\",\n",
        "    \"Apologies, but I am not able to provide assistance on this matter. Please let me know if you require help with event tickets.\",\n",
        "    \"Unfortunately, I cannot assist with this. However, I am here to help with any event ticket-related concerns you may have.\",\n",
        "    \"Regrettably, I am unable to assist with this request. If there's anything I can do regarding event tickets, feel free to ask.\",\n",
        "    \"I regret that I am unable to assist in this case. Please reach out if you need support related to event tickets.\",\n",
        "    \"Apologies, but this falls outside the scope of my support. I\u2019m here if you need any help with event ticket issues.\",\n",
        "    \"I'm sorry, but I cannot assist with this particular topic. If you have questions about event tickets, I\u2019d be glad to help.\",\n",
        "    \"I regret that I\u2019m unable to provide assistance here. Please let me know how I can support you with event ticket matters.\",\n",
        "    \"Unfortunately, I am not equipped to assist with this. If you need help with event tickets, I am here for that.\",\n",
        "    \"I apologize, but I cannot help with this request. However, I\u2019d be happy to assist with anything related to event tickets.\",\n",
        "    \"I\u2019m sorry, but I\u2019m unable to support this request. If it\u2019s about event tickets, I\u2019ll gladly help however I can.\",\n",
        "    \"This matter falls outside the assistance I can offer. Please let me know if you need help with event ticket-related inquiries.\",\n",
        "    \"Regrettably, this is not something I can assist with. I\u2019m happy to help with any event ticket questions you may have.\",\n",
        "    \"I\u2019m unable to provide support for this issue. However, I can assist with concerns regarding event tickets.\",\n",
        "    \"I apologize, but I cannot help with this matter. If your inquiry is related to event tickets, I\u2019d be more than happy to assist.\",\n",
        "    \"I regret that I am unable to offer help in this case. I am, however, available for any event ticket-related questions.\",\n",
        "    \"Unfortunately, I\u2019m not able to assist with this. Please let me know if there\u2019s anything I can do regarding event tickets.\",\n",
        "    \"I'm sorry, but I cannot assist with this topic. However, I\u2019m here to help with any event ticket concerns you may have.\",\n",
        "    \"Apologies, but this request falls outside of my support scope. If you need help with event tickets, I\u2019m happy to assist.\",\n",
        "    \"I\u2019m afraid I can\u2019t help with this matter. If there\u2019s anything related to event tickets you need, feel free to reach out.\",\n",
        "    \"This is beyond what I can assist with at the moment. Let me know if there\u2019s anything I can do to help with event tickets.\",\n",
        "    \"Sorry, I\u2019m unable to provide support on this issue. However, I\u2019d be glad to assist with event ticket-related topics.\",\n",
        "    \"Apologies, but I can\u2019t assist with this. Please let me know if you have any event ticket inquiries I can help with.\",\n",
        "    \"I\u2019m unable to help with this matter. However, if you need assistance with event tickets, I\u2019m here for you.\",\n",
        "    \"Unfortunately, I can\u2019t support this request. I\u2019d be happy to assist with anything related to event tickets instead.\",\n",
        "    \"I\u2019m sorry, but I can\u2019t help with this. If your concern is related to event tickets, I\u2019ll do my best to assist.\",\n",
        "    \"Apologies, but this issue is outside of my capabilities. However, I\u2019m available to help with event ticket-related requests.\",\n",
        "    \"I regret that I cannot assist with this particular matter. Please let me know how I can support you regarding event tickets.\",\n",
        "    \"I\u2019m sorry, but I\u2019m not able to help in this instance. I am, however, ready to assist with any questions about event tickets.\",\n",
        "    \"Unfortunately, I\u2019m unable to help with this topic. Let me know if there's anything event ticket-related I can support you with.\"\n",
        "]\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_path = '/content/mydrive/MyDrive/Chatbot_Query_Classifier/chatbot_query_classifier_distilbert_model'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Prediction function\n",
        "def predict_OOD(query: str):\n",
        "    # Tokenize and move input to device\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=32)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Get model output\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    class_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return class_id  # 0 = No, 1 = Yes"
      ],
      "metadata": {
        "id": "Tvd27B6gFSm5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "    user_input = input(f\"[{i+1}/2] Your query: \")\n",
        "\n",
        "    if user_input.lower() in ['exit', 'quit']:\n",
        "        print(\"\ud83d\udc4b Exiting the chatbot. Have a great day!\")\n",
        "        break\n",
        "\n",
        "    prediction = predict_OOD(user_input)\n",
        "\n",
        "    if prediction == 1:\n",
        "        # If OOD, show random polite fallback\n",
        "        fallback_response = random.choice(responses)\n",
        "        print(f\"\\n\ud83d\udd0d Prediction: Out of Domain \u274c\\n\ud83d\udcac Response: {fallback_response}\\n\")\n",
        "    else:\n",
        "        # If in-domain, respond accordingly\n",
        "        print(f\"\\n\ud83d\udd0d Prediction: In Domain \u2705\\n\ud83d\udcac Response: This seems like a valid event ticket query. How can I assist you further?\\n\")\n",
        "\n",
        "print(\"\u2705 Done. Thank you!\")"
      ],
      "metadata": {
        "id": "CzVOiWmEFSi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c1107b-4262-4f6a-c979-60dcab9e5038"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/2] Your query: How can i sell my ticket?\n",
            "\n",
            "\ud83d\udd0d Prediction: In Domain \u2705\n",
            "\ud83d\udcac Response: This seems like a valid event ticket query. How can I assist you further?\n",
            "\n",
            "[2/2] Your query: Explain how large language model works?\n",
            "\n",
            "\ud83d\udd0d Prediction: Out of Domain \u274c\n",
            "\ud83d\udcac Response: Apologies, but this request falls outside of my support scope. If you need help with event tickets, I\u2019m happy to assist.\n",
            "\n",
            "\u2705 Done. Thank you!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"https://www.icegif.com/wp-content/uploads/2024/12/thank-you-icegif-11.gif\" width=\"400\"/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "fQCR-bCb71Uf"
      }
    }
  ]
}